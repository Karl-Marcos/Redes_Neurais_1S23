<h2 align="center"> REDES NEURAIS ARTIFICIAIS </h2>

## Experimentos
Os experimentos foram realizados nos notebooks abaixo, que são arquivos **.ipynb** <br>
- <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.01%20-%20derivadas.ipynb">Experimento R.01 - Recordando Derivadas </a> <br>
Esse notebook contém uma breve revisão do conceito de derivada, além de como calculá-las numericamente.

- <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.02%20-%20classes.ipynb"> Experimento R.02 - Introdução a Classes </a> <br>
Esse notebook é uma aula introdutória à estrutura de Classes em python.

- <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.03%20-%20construindo%20um%20grafo%20automaticamente.ipynb">Experimento R.03 - Construindo um grafo automaticamente
 </a> <br>
 Aqui aprendemos a utilizar a estrutura de classes para automatizar o algoritmo de plotar um grafo, que vamos utilizar para representar nossas redes.
 
 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.04%20-%20computando%20gradientes%20locais.ipynb"> Experimento R.04 - Computando gradientes locais </a> <br>
Esse experimento consiste em um algoritmo para computar os gradientes de cada um dos vértices da rede em relação ao vértice folha. Esse algoritmo é chamado de **backpropagation**

 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.05%20-%20finalizando%20a%20classe%20Valor.ipynb"> Experimento R.05 - Finalizando a classe Valor </a> <br>
Agora completamos a classe Valor, para que possamos fazer operações que serão necessárias para a rede neural, como somar e multiplicar instâncias, multiplicar e adicionar uma constante, fazer a operação de exponenciação, etc.

 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.06%20-%20redes%20neurais%20artificiais.ipynb"> Experimento R.06 - Redes Neurais Artificiais </a> <br>
Finalmente podemos usar a classe valor para construir nossa primeira rede neural, uma **Multilayer Perceptron (MLP)**.

 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.07%20-%20treinando%20uma%20rede%20neural.ipynb"> Experimento R.07 - Treinando uma Rede Neural </a> <br>
O próximo passo é utilizar o forward pass e o backpropagation para treinar a rede neural

 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/experimento%20R.08%20-%20treinando%20uma%20rede%20neural%20com%20pytorch.ipynb"> Experimento R.08 - Treinando uma Rede Neural usando pytorch </a> <br>
Agora que já sabemos como funciona a programação de uma Rede Neural da forma mais fundamental, vamos aprender a usar as ferramentas mais avançadas prontas para treinar Redes Neurais. Para isso, vamos utilizar a biblioteca **pytorch**.

## Arquivos Python <br>

 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/funcoes.py"> funcoes.py </a> Contém todas as funções em python usadas nos experimentos <br>
 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/constantes.py"> constantes.py </a> Contém algumas constantes utilizadas nos experimentos
 - <a href="https://github.com/Karl-Marcos/Redes_Neurais_1S23/blob/main/RedesNeurais/classes.py"> classes.py </a> Contém as classes utilizadas nos experimentos
